[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Microeconomics 1",
    "section": "",
    "text": "Note\n\n\n\nBased on Alexander Wolitzky lecture slides, available at MIT Opencourseware.\nCC BY-NC-SA 4.0 Legal Code | Attribution-NonCommercial-ShareAlike 4.0 International | Creative Commons. See here for more information.\n\n\n\nSyllabus 2024.1\n\n\n\n\n\n\nJoin the 2024.1 class WhatsApp group for the first part of the course.\n\n\n\n\n\n\n\n\n\n\n\n\nLEC #\nTOPICS\nREADINGS\n\n\n\n\n1, 2\nChoice, Preference, and Utility\n[MWG] Chapter 1.\n[Kreps] Chapters 1 and 2.\n\n\n3–5\nConsumer Theory and its Applications\nConsumer Theory\n[MWG] Chapters 2 and 3.\n[Kreps] Chapters 3, 10, and 11.\nApplications of Consumer Theory\n[MWG] Chapter 4.\n\n\n6, 7\nProducer Theory and Monotone Methods\n[MWG] Chapter 5.\n\n\n8–11\nChoice Under Uncertainty\n[MWG] Chapter 6.\n[Kreps] Chapters 5 and 6.\n\n\n12\nDynamic Choice\n[Kreps] Chapter 7.",
    "crumbs": [
      "Syllabus 2024.1"
    ]
  },
  {
    "objectID": "choice-pref-utility.html",
    "href": "choice-pref-utility.html",
    "title": "1  Choice, Preferences and Utility",
    "section": "",
    "text": "1.1 Decision Theory\nWe begin with decision theory. To build a theory of individual choice, we need some assumptions:",
    "crumbs": [
      "Lectures 1 – 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Choice, Preferences and Utility</span>"
    ]
  },
  {
    "objectID": "choice-pref-utility.html#decision-theory",
    "href": "choice-pref-utility.html#decision-theory",
    "title": "1  Choice, Preferences and Utility",
    "section": "",
    "text": "1. Choices are possible\n\nSeems obvious, but sets us apart from many models from 19th century sociology\nBig discussions here. See Determined: a science of life without free will (Sapolsky, 2023)\nImportant link to theory of agency in biology\nWe usually model this through restrictions (see point 4 below)\n\n\n\n2. There is a defined subject that makes decisions, in some circumstance\n\n(Usually) It’s and individual, not a set of individuals such as family nor parts of an individual such as Id and Ego – but there has been much development in this direction.\nWe just need to separate individual from the whole society (or there would be no need to study interactions)\nThis is not the selfish agent assumption, which we can also make in particular settings\n\n\n\n3. Choices are made according to some criteria\n\nThey are not purely random (at least not necessarily)\nThis is the same as saying as there is some objective. Could be anything: profit, utility, leisure, stability, time with loved ones, watching as many world cup matches as possible…\n\n\n\n4. Choices are subject to constraints\n\nOne cannot simply choose ‘everything’. At the very least there is the opportunity cost of time.\nThis is not necessarily a budget restriction: could be time, attention, memory, information, ability to process information, or external factors such as physical environment or laws, or simply other agents.\nIn this course, we will consider a budget constraint, but this is just a particular case, and the absent restrictions are as important as the one(s) we will consider!\n\n\n\n5. Consistency requirement: equilibrium\n\nEveryone is choosing according to the four previous assumptions at any point in time.\nIn other words: given the criteria and the restrictions at some point in time, no one would like to change their decision at that moment.\nFor a given individual, part of the environment is ‘other individuals making choices, and maybe they’re even taking my actions into account’\nThis is NOT about absence of movement or change. There could be mistakes and regrets.\n\nWe typically write the first four points as\n\n“Choose x to solve \\max u(x) subject to restrictions on x”\n\nThen we move on to interaction: no individual incentive to deviate, given what others are doing. In short, our structure is optimization + equilibrium. This is very general. Hard to work without it.",
    "crumbs": [
      "Lectures 1 – 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Choice, Preferences and Utility</span>"
    ]
  },
  {
    "objectID": "choice-pref-utility.html#about-assumptions",
    "href": "choice-pref-utility.html#about-assumptions",
    "title": "1  Choice, Preferences and Utility",
    "section": "1.2 About assumptions",
    "text": "1.2 About assumptions\nWe’ve barely begun and already have some big assumptions.\nWe’ll make many other assumptions along the way. Pay attention to them: assumptions must be clearly understood. We usually write A \\Rightarrow B: we must be able to understand what happens (B) under some circunstances (A). This is NOT them same as stating B (think of the first welfare theorem).\nAssumptions have a tradeoff. On one hand, they take away generality: if we assume economic agents have perfect memory, we must be cautious when applying our model to agents without perfect memory. On the other hand, they allow us to better understand a (more restricted) setting.\nThis is the tradeoff of the lab rat. It’s easier to study, and we learn a lot from it, but must be aware of its limits. In our case, ‘homo economicus’, for example:\n\nSimplest economic model: maximize utility subject only to a budget constraint.\n\nWe study the homo economicus hoping to learn something about its distant cousin: homo sapiens. The more realist economic agent from behavioral economics is our ‘lab monkey’: the same tradeoff applies.\nIs there a way around this tradeoff? No: it comes from our own limitations, as we cannot pay attention and process all available information. Think for a moment far from economics: zebras and lions. Where are their eyes placed? They “choose” to focus on some specific type of information, and give up on many things. It works according to some specific criterion: survival.\nIn economics (and any other field of science), we will make assumptions, whether it’s clear or not. The problem is the criterion we use to evaluate them. No “given” criterion such as survival. Major discussion about criteria, for every research question.\nWe may put it another way: there is a tradeoff to realism. If it’s too much: can’t really understand what’s going on, can’t make predictions. Borges’ map. If it’s too little: you’ll understand clearly something not relevant to your research question. Drunkard looking for his keys under the lamp post, not where he lost them.\nIn the end of the day, we use approximations, and we want predictions that can be tested to see whether these approximations are good enough. Keep in mind that external validity is always an issue, even when we have good empirical results, and this depends on how restrictive our assumptions are (must be extra careful with observational data!).\nLastly, a point about representation: a model of reality is different from reality. Implication: solving a model in decision theory is different from actually making that decision (same reasoning holds for anything else in science). Think of catching an object thrown to you (no actual functional analysis problem) or buying stuff at the grocery store (no actual lagrangian).\nThis goes back to theory of agency in biology: consciousness, representation and abstraction. Important: if the modeler knows more than the agents in the model, this must be modeled too! It’s some form of restriction.\nAs for criticism: when we criticize a model, we either say “A is not the relevant setup to consider” or “A does not really imply B”. Considering a different setup (A' instead of A) is not really a criticism – it’s just ‘doing something else’. Think of political and relief maps, or flat maps and globes.\n\n\n\n\n\n\nWe always have to ask: What are we building our models and theories for? What do we want to understand?\nModels are made to be used, not to be believed\nIf they help us with something relevant, they’re doing their job: increase food production, cure a disease, decrease unemployment, etc.\n\n\n\n\nMathematics\nOur assumptions often generate a setup that may be analyzed mathematically. Our optimization problem will be written as something similar to:\n\\max_{\\{x\\}} {f(x)} subject to some restriction\ng(x) &lt; 0\nYet, it is important to notice the difference between language and tools. We use mathematical language as in the example above. This does not mean we’re using any mathematical tools yet: this could be written in plain English. Often we will use actual mathematical tools: if f and g are differentiable functions, then we may use first-order conditions.\n\n\nAn additional point\n\nAs science advances, it becomes more continuous, and less discrete.\nIn economics, we fight too often over petty details (Freud: narcissism of small differences.)\n\nWe will start with the most basic model: the traditional homo economicus, our lab rat, whose only restriction is budgetary.\n\n\nAn example\nLionel Page fascinating explanation of Prospect Theory:\n\n\n\nProspect Theory\n\n\nThis is the most cited paper in economics: people value what they have by considering it as a gain or a loss relative to a subjective “reference point”. This point may be status quo, expectations, aspirations: not defined / agreed upon.\nReference dependent preferences are a cognitive flaw? The biological basis of economic behavior (Robson, 2001): subjective satisfaction can be seen as an informative signal that helps us identify the best option. Eating, sleeping and having sex ‘feel good’ because they help us survive: subjective satisfaction is informative signal.\n\n\n\n\n\nBut brain (neurological processes, more generally) have constraints when generating signals of satisfaction:\n\nSignals must be bounded because there is a limited number of neurons to process them\nSignals are not perfectly precise (drugs as hijacking)\n\nHence: we are more likely to make mistakes when options are close.\n\n\n\n\n\nCan your system of perception be improved to reduce mistakes?\nYes. When the slope of subjective satisfaction increases, it reduces mistakes between options that are close.\n\n\n\n\n\nBut satisfaction is bounded: physical limit to pleasure (that is, to informativeness of signals). Then satisfaction cannot have a super high slope everywhere.\nThe question becomes: Where should the slope of subjective satisfaction be steeper to limit mistakes? The optimal solution is that it should be steeper where you are more likely to face options to choose from!\n\n\n\n\n\nSee also Rayo and Becker (2007) and Netzer (2009).\n\nSupport from neuroscience: sensory systems respond to stimuli by following their distribution.\nReference-dependent preferences are not a cognitive flaw. “They are an optimal solution, under irreducible biological constraints faced by our perceptual systems.” \\rightarrow Efficient coding.\nReference point is an expectation.\nRecent literature in economics and neuroscience.\n\nIn short: again, we have the problem “Choose x to solve \\max u(x) subject to restrictions on x”. Restrictions that don’t show up are as relevant as those that show up.\nFar from the only example… in fact, hard to think of economics without this structure (and hard in social sciences in general). What decisions are automatic, and what are well-thought? (Do you think about where to brush your teeth every day?)\n\n\nSome difficult words\nThis setup is an approach based on optimization and equilibrium. Sometimes we talk about rational agents. All these words have multiple meanings and lead to confusion.\n\nOptimization simply means that individuals make choices according to some criteria, given the relevant restrictions. But sometimes used as ‘perfect optimization’ or ‘hyper rationality’, which needs not be the case.\nRationality has different uses within microeconomics. First: similar to optimization under restrictions. Second: a particular set of basic assumptions on the decision-maker. We will use the latter. Sometimes (very often!) used in the sense of ‘super computational power’. This is usually the case in basic microeconomics: we only have a budget constraint, meaning there are no cognitive constraints. This is often referred to as ‘homo economicus’ of ‘homo rationalis’ and is simply our lab rat: we study it not because it’s realistic, but because it’s much easier to study, and many things we learn carry over to ‘actual’ humans.\nEquilibrium means there is no unilateral incentive to change in a given context. Sometimes used, even within economics, in the sense of physics: lack of movement, or some very stable movement. This is NOT the meaning of the word in microeconomics.",
    "crumbs": [
      "Lectures 1 – 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Choice, Preferences and Utility</span>"
    ]
  },
  {
    "objectID": "choice-pref-utility.html#utility-maximization",
    "href": "choice-pref-utility.html#utility-maximization",
    "title": "1  Choice, Preferences and Utility",
    "section": "1.3 Utility Maximization",
    "text": "1.3 Utility Maximization\nBasic model of individual choice:\n\nA decision-maker (DM) must choose one alternative x from a set X.\nChooses to maximize a utility function u.\nu specifies how much utility DM gets from each alternative: u: X \\rightarrow \\mathbb{R}\n\nExample: DM chooses whether to eat an apple or a banana.\nX =\\{apple, banana\\}\nUtility function might say u(apple) = 7, u(banana) = 12. Observe that we already started to use mathematics – but only as language.\n\nWhat do Utility Levels Mean? Hedonic Interpretation\nUtility is an objective measure of individual’s well-being.\n\nNature has placed mankind under the governance of two sovereign masters, pain and pleasure. It is for them alone to point out what we ought to do… By the principle of utility is meant that principle which approves or disapproves of every action whatsoever according to the tendency it appears to have to augment or diminish the happiness of the party whose interest is in question: or, what is the same thing in other words to promote or to oppose that happiness. I say of every action whatsoever, and therefore not only of every action of a private individual, but of every measure of government.\nJeremy Bentham\n\n“u (apple) = 7, u (banana) = 12” \\rightarrow apple gives 7 units of pleasure, banana gives 12 units of pleasure. This is not the standard way economists think about utility.\n\n\nWhat do Utility Levels Mean? Revealed-Preference Interpretation\nUtility represents an individual’s choices.\n\nIndividual choices are primitive data that economists can observe.\nChoices are taken to reveal individual’s preferences.\nUtility is a convenient mathematical construction for modeling choices and preferences.\n\n\n\n\n\n\n\n“u (apple) = 7, u (banana) = 12” \\rightarrow individual prefers bananas to apples.\n“u (apple) = 2, u (banana) = 15” \\rightarrow individual prefers bananas to apples.",
    "crumbs": [
      "Lectures 1 – 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Choice, Preferences and Utility</span>"
    ]
  },
  {
    "objectID": "choice-pref-utility.html#choice",
    "href": "choice-pref-utility.html#choice",
    "title": "1  Choice, Preferences and Utility",
    "section": "1.4 Choice",
    "text": "1.4 Choice\nHow can an individual’s choices reveal her preferences? A choice structure (or choice dataset) (\\mathscr{B}, C) consists of:\n\nA set \\mathscr{B} of choice sets B \\subseteq X.\nA choice rule C that maps each B \\in \\mathscr{B} to non-empty set of chosen alternatives C(B) \\subseteq B. C is a correspondence.\n\nInterpretation: C(B) is the set of alternatives the DM might choose from B.",
    "crumbs": [
      "Lectures 1 – 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Choice, Preferences and Utility</span>"
    ]
  },
  {
    "objectID": "choice-pref-utility.html#preference",
    "href": "choice-pref-utility.html#preference",
    "title": "1  Choice, Preferences and Utility",
    "section": "1.5 Preference",
    "text": "1.5 Preference\nGoal: relate observable choice data to preferences over X.\nA preference relation \\succcurlyeq is a binary relation on X.\n\n\n\n\n\n\nMeaning\n\n\n\n“x \\succcurlyeq y” means “x is weakly preferred to y”\n\n\nGiven preference relation \\succcurlyeq, define:\n\nStrict preference (\\succ): x \\succ y \\iff x \\succcurlyeq y but not y \\succcurlyeq x.\nIndifference (∼): x ∼ y \\iff x \\succcurlyeq y and y \\succcurlyeq x.\n\nThink a little bit about logic and set theory here.\n\nRational Preferences\nTo make any progress, need to impose some restrictions on preferences.\nMost important: rationality.\n\nDefinition 1.1 A preference relation \\succcurlyeq is rational if it satisfies:\n\nCompleteness: for all x, y, x \\succcurlyeq y or y \\succcurlyeq x.\nTransitivity: for all x, y, z, if x \\succcurlyeq y and y \\succcurlyeq z, then x \\succcurlyeq z.\n\n\nIf \\succcurlyeq is rational, then \\succ and \\sim are also transitive. (Prove this!)\nHard to say much about behavior of irrational DM.\n\n\nMaximizing a Preference Relation\nOptimal choices according to \\succcurlyeq:\n\nC^*(B,\\succcurlyeq) = \\{x \\in B: x \\succcurlyeq \\in y, \\forall y \\in B\\}\n\n\\succcurlyeq rationalizes choice data (\\mathscr{B}, C) if C(B) = C^*(\\mathscr{B}, \\succcurlyeq) for all B \\in \\mathscr{B}.\n\n\nFundamental Question of Revealed Preference Theory\nWhen does choice data reveal that individual is choosing according to rational preferences?\n\nDefinition 1.2 Given choice data (\\mathscr{B}, C), the revealed preference relation \\succcurlyeq^* is defined by x \\succcurlyeq^* y \\iff there is some B \\in \\mathscr{B} with x,y \\in B and x \\in C(B).\n\nx is weakly revealed preferred to y if x is ever chosen when y is available. Notice that this allows for y \\in C(B) as one may have x ∼ y.\nx is strictly revealed preferred to y if there is some B \\in \\mathscr{B} with x, y \\in B, x \\in C(B) and y \\notin C(B).\n\n\n\n\nWARP\nKey condition on choice data for \\succcurlyeq^* to be rational and generate observed data: weak axiom of revealed preference (WARP).\n\nDefinition 1.3 Choice data (B,C) satisfies WARP if whenever there exists B \\in \\mathscr{B} with x, y \\in B and x \\in C(B), then for all B' \\in \\mathscr{B} with x,y \\in B', it is not the case that both y \\in C(B') and x \\notin C(B').\n\n\n\n\n\n\n\nMeaning\n\n\n\n“If x is weakly revealed preferred to y, then y cannot be strictly revealed preferred to x”\n\n\n\n\n\n\n\n\nExample\n\n\n\n\nX = \\{x,y,z\\}\n\n\n\\mathscr{B} = \\{\\{x,y\\}, \\{x,y,z\\}\\}\n\n\nChoice rule C_1: C_1(\\{x,y\\}) = \\{x\\}, C_1 (\\{x,y,z\\}) = \\{x\\}\nSatisfies WARP: x is weakly revealed preferred to y and z, nothing is strictly revealed preferred to x\nChoice rule C_2: C_2(\\{x,y\\}) = \\{x\\}, C_2(\\{x,y,z\\}) = \\{x,y\\}.\nViolates WARP: y is weakly revealed preferred to x, x is strictly revealed preferred to y. This is Exercise 1C1 (MWG).\n\n\n\n\n\nFundamental Theorem of Revealed Preference Theory\n\nTheorem 1.1 If choice data (\\mathscr{B}, C) satisfies WARP and includes all subsets of X of up to 3 elements, then \\succcurlyeq^* is rational and rationalizes the data: that is, C^* (B, \\succcurlyeq^*) = C(B). Furthermore, this is the only preference relation that rationalizes the data (MWG Proposition 1.D.2). Conversely, if the choice data violates WARP, then it cannot be rationalized by any rational preference relation. (MWG Proposition 1D1).\n\nFor the first part: Remember \\mathscr{B} is a set of sets: this condition states that it must include all sets of up to three elements. Check MWG example 1D1 to see that we cannot drop this assumption.\n\n\n\n\n\n\nProof\n\n\n\n\nLet’s prove the first part.\n\nWe need to show that:\n\n\\succcurlyeq^* is rational;\nC^* (B, \\succcurlyeq^*) = C(B);\n\\succcurlyeq^* is the only preference relation that satisfies ii.\n\nFor item (i), we must show that \\succcurlyeq* is complete and transitive.\nComplete. Take some \\{x,y\\} \\in \\mathscr{B}. This holds because \\{x,y\\} has only two elements. Then either x \\in C({x,y}) or y \\in C(\\{x,y\\}) (or both). In the first case, x \\succcurlyeq^* y. In the second case, y \\succcurlyeq^* x. Hence \\succcurlyeq^* is complete.\nTransitive. Take x \\succcurlyeq^* y and y \\succcurlyeq^* z. Consider \\{x,y,z\\ \\in \\mathscr{B}\\} (again, it has no more than three elements, so it belongs to \\mathscr{B}). We have to show that x \\in C(\\{x,y,z\\}) because this implies x \\succcurlyeq^* y: transitivity.\nWe know that C(\\{x,y,z\\}) \\neq \\varnothing.\n\nIf y \\in C(\\{x,y,z\\}): since x \\succcurlyeq^* y, the weak axiom yields x \\in C(\\{x,y,z\\}).\nIf z \\in C(\\{x,y,z\\}): since y \\succcurlyeq^* z, the weak axiom yields y \\in C(\\{x,y,z\\}), and from the previous line we have x \\in C(\\{x,y,z\\}). In any case, x \\in C(\\{x,y,z\\}), as we wanted to show.\n\nThis concludes the proof of item (i).\nFor item (ii), we proceed in two steps.\nFirst: suppose x \\in C(B). Then x \\succcurlyeq^* y for all y \\in B. Hence x \\in C^*(B,\\succcurlyeq^*). In short: every element x that belongs to C(B) also belongs to C^*(B,\\succcurlyeq^*). In other words, C(B) \\subset C^*(B,\\succcurlyeq^*).\nSecond: suppose now x \\in C^*(B,\\succcurlyeq^*).\nThen x \\succcurlyeq^* y for all y \\in B, as above.\nHence for each y \\in B, there exists some B_y \\in \\mathscr{B} such that x,y \\in B_y and x \\in C(B_y): at the very least, one may choose B_y = \\{x,y\\}, which has only two elements and therefore belongs to \\mathscr{B}.\nSince C(B) \\neq \\varnothing, the weak axiom implies x \\in C(B), by the same reasoning as in part i: whatever y may belong to C(B), it cannot be revealed as preferred to x because x \\in C(B_y) and hence x \\in C(B).\nIn short: x \\in C^*(B,\\succcurlyeq^*) \\implies x \\in C(B), or C^*(B,\\succcurlyeq^*) \\subset C(B).\nTaking these two steps together, we conclude that C(B) = C^*(B,\\succcurlyeq^*), finishing the proof of item ii.\nFor item (iii), remember that \\mathscr{B} includes all two-element subsets of X. Hence the choice structure C(\\quad) determines the pairwise preference over X of any rationalizing preference.\nQED.\n\nThe second part may be written as: if preferences are rational, then choice data (\\mathscr{B},C) satisfies WARP. Let’s prove this.\n\nConsider B \\in \\mathscr{B} such that x, y \\in B, and x \\in C^*(B,\\succcurlyeq). Then x \\succcurlyeq y. (“x is weakly revealed preferred to y”)\nConsider B' \\in \\mathscr{B} such that x, y \\in B', and y \\in C^*(B',\\succcurlyeq). Then y \\succcurlyeq z for all z \\in B'.\nTransitivity then implies x \\succcurlyeq z for all z \\in B'.\nBut this is the same as saying x \\in C^*(B',\\succcurlyeq).\nThat is, we cannot find any B' such that y \\succ x. (“y) cannot be strictly revealed preferred to x”). Hence, WARP is satisfied.\nQED.\n\n\nTheorem tells us how individual’s choices reveal her preferences: as long as choices satisfy WARP, can interpret choices as resulting from maximizing a rational preference relation.\nWe may conclude that if \\mathscr{B} includes all subsets of X, then choice and preferences work together just fine. But this is too restrictive: think of budget sets.\nWe use then the Strong Axiom of Revealed Preference, a “recursive closure” of the weak axiom. If x is directly or indirectly revealed preferred to y, then y cannot be directly revealed preferred to x. The Strong Axiom is more restrictive in general than the Weak Axiom (but they are equivalent for two goods). The Strong Axiom is a necessary and sufficient condition for choices to be generated by rational preferences.\n\nQuestion: choices usually follow WARP?\nYes – even more than that. Bedi and Burghart (2018):\n\n“Choices made under the influence of THC, MDMA, and placebo were all GARP compliant. Thus, even when participants were acutely intoxicated with THC or MDMA, their choices remained consistent with the tenets of neoclassical choice theory.”\n\nGARP is the Strong Axiom that allows for non-unique optimal choices.\n\n\n\nPreference and Utility\nNow that know how to infer preferences from choice, next step is representing preferences with a utility function.\n\nDefinition 1.4 A utility function u : X \\rightarrow \\mathbb{R} represents preference relation \\succcurlyeq if, for all x,y, x \\succcurlyeq y \\iff u(x) \\geq u(y)\n\nbanana \\succcurlyeq apple is represented by both:\nu(apple) = 7, \\quad u(banana) = 12 u(apple) = 2, \\quad u(banana) = 15\nIf u represents \\succcurlyeq, so does any strictly increasing transformation of u.\nRepresenting a given preference relation is an ordinal property. The numerical values of utility are cardinal properties.\n\nWhat Preferences have a Utility Representation?\n\nTheorem 1.2 Only rational preferences relations can be represented by a utility function (MWG Proposition 1B2). Conversely, if X is finite, any rational preference relation can be represented by a utility function (MWG exercise 1B5 - ‘X finite’ is only one possibility).\n\n\n\n\n\n\n\nProof\n\n\n\n\nLet’s prove the first part.\n\nWe may write it as: \\succcurlyeq is represented by utility function implies \\succcurlyeq is rational.\nTo show it’s rational, we have to show \\succcurlyeq are complete and transitive.\nLet’s show first \\succcurlyeq are complete. Consider x,y \\in X.\nu(.) \\in \\mathbb{R} implies that necessarily either u(x) \\geq u(y) or u(y) \\geq u(x). In the first case, by definition of u, we have x \\succcurlyeq y. Analogously, in the second case we have y \\succcurlyeq x. Hence \\succcurlyeq is complete.\nLet’s show now \\succcurlyeq are transitive. Take x,y,z \\in X such that x \\succcurlyeq y and y \\succcurlyeq z. We have to show that x \\succcurlyeq z.\nBy definition of u(.), it follows that u(x) \\geq u(y) and u(y) \\geq u(z). It then follows from the structure of the real numbers that u(x) \\geq u(z). Again, use the definition of u(.) to conclude that x \\succcurlyeq z. This is what we wanted to show, concluding the proof.\nQED.\n\n\n\n\nWhat Goes Wrong with Infinitely Many Alternatives?\nLexicographic preferences: dictionary system – e.g., “I’m not going by plane”.\n\nX = [0,1] \\times [0,1]\n\n(x_1, x_2) \\succcurlyeq (y_1, y_2) if either\n\nx_1 &gt; y_1 or\nx_1 = y_1 and x_1 \\geq y_2\n\nMaximize first component. In case of tie, maximize second component.\n\nTheorem 1.3 Lexicographic preferences cannot be represented by a utility function.\n\nThis is on MWG page 46.\n\n\n\n\n\n\nProof\n\n\n\nLet’s prove this by contradiction. Assume there is a utility function representing the lexicographic preferences \\succcurlyeq.\nFix some x_1 \\in \\mathbb{R}. Then:\n\nu(x_1, 2) &gt; u(x_1, 1)\n\nBoth u(x_1, 2) and u(x_1, 1) are real number. We will use the following mathematical result: we can find a rational number between any two real numbers.\nLet’s call this rational number r(x_1):\n\nu(x_1, 2) &gt; r(x_1) &gt; u(x_1, 1)\n\nNotice now that if x_1 &gt; x^{'}_{1}, then r(x_1) &gt; u(x_1, 1) &gt; u(x^{'}_{1},2) &gt; r(x^{'}_{1}).\nIn short, x_1 &gt; x^{'}_{1} \\implies r(x_1) &gt; r(x^{'}_{1}).\nThis means that r(.) is a strictly increasing function, and hence it is a bijection from \\mathbb{R} to \\mathbb{Q}.\nBut this is not possible.\nQED.\n\n\n\n\n\nContinuous Preferences\nWhat if rule out discontinuous preferences?\n\nDefinition 1.5 For X \\subseteq \\mathbb{R}^n, preference relation \\succcurlyeq is continuous if whenever x^m \\rightarrow x, y^m \\rightarrow y, and x^m \\succcurlyeq y^m for all m, we have x \\succcurlyeq y.\n\n\n\n\n\n\n\nProof\n\n\n\nLexicographic preferences are not continuous: see example 3C1 cont.\nLet’s show this. Consider two sequences of bundles:\n\nx_n = \\left(\\frac{1}{n},0\\right)\n \ny_n = (0,1)\n\nFor any n we choose, we have 1/n &gt; 0, and hence x_n \\succ y_n. But lim_{n \\rightarrow \\infty}{x_n} = (0,0) \\prec (0,1) = lim_{n \\rightarrow \\infty}{y_n}\nThat is, preference reverts in the limit: continuity does not hold, and hence \\succcurlyeq are not continuous.\nQED.\n\n\n\nTheorem 1.4 For X \\subseteq \\mathbb{R}^n, any continuous, rational preference relation can be represented by a (continuous) utility function.\n\nThis is MWG Proposition 3.C.1 – a bit advanced.\n\n\n\n\n\n\nProof\n\n\n\nThe general proof is difficult. Let’s show a sketch, assuming additionally that preferences are monotone.\nConsider only two goods (this is without loss of generality). For any \\alpha \\geq 0, define the bundle (\\alpha, \\alpha).\nPick some x = (x_1,x_2) \\in \\mathbb{R}^2_+. Notice that monotonicity implies x \\succcurlyeq (0,0).\nNotice also that if \\left(\\overline{\\alpha}, \\overline{\\alpha}\\right) \\gg (x_1, x_2), then monotonicity implies \\left(\\overline{\\alpha}, \\overline{\\alpha}\\right) &gt; (x_1, x_2).\nOne may show that there is only one value of \\alpha \\in [0,\\overline{\\alpha}] such that indifference holds.\nWe will call it \\alpha(x):\n\n\\left(\\alpha(x),\\alpha(x)\\right) \\sim (x_1,x_2)\n Take u(x) = \\alpha(x). This is our utility function.\nQED.\n\n\nNotice that this is very general. Assumptions are not very restrictive (not even X \\subseteq \\mathbb{R}^n).\n\n\nReview of Revealed Preference Theory\n\nIf choice data satisfies WARP, can interpret as resulting from maximizing a rational preference relation.\nIf set of alternatives is finite or preferences are continuous, can represent these preferences with a utility function.\nUtility function is just a convenient mathematical representation of individual’s ordinal preferences.\nUtility may or may not be correlated with pleasure/avoidance of pain.",
    "crumbs": [
      "Lectures 1 – 2",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Choice, Preferences and Utility</span>"
    ]
  },
  {
    "objectID": "prop-pref-utilityfun.html",
    "href": "prop-pref-utilityfun.html",
    "title": "2  Properties of Preferences and Utility Functions",
    "section": "",
    "text": "Setting/Notation\nFor rest of lecture, assume X \\subseteq \\mathbb{R}^n.",
    "crumbs": [
      "Lectures 1 – 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Properties of Preferences and Utility Functions</span>"
    ]
  },
  {
    "objectID": "prop-pref-utilityfun.html#monotonicity",
    "href": "prop-pref-utilityfun.html#monotonicity",
    "title": "2  Properties of Preferences and Utility Functions",
    "section": "2.1 Monotonicity",
    "text": "2.1 Monotonicity\n\n\n\n\n\n\nMeaning\n\n\n\n“All goods are desirable”\n\n\n\nPreferences\n\nDefinition 2.1 (MWG 3B2) \n\\succcurlyeq is monotone if x \\geq y implies x \\succcurlyeq y\n\\succcurlyeq is strictly monotone if x &gt; y implies x \\succ y\n\nFor example, strict monotonicity implies (2,3,4) \\succ (1,3,4).\n\n\nUtility\nIf preferences are monotone, what does that mean for the utility function?\n\nTheorem 2.1 (MWG Exercise 3B1) Suppose utility function u represents preferences \\succcurlyeq. Then:\nu non-decreasing \\iff\\succcurlyeq monotone\nu strictly increasing \\iff\\succcurlyeq strictly monotone\n\n\n\n\n\n\n\nProof\n\n\n\nLet’s prove this.\n\nFor the first part:\n\nu non-decreasing \\iff\n[x \\geq y \\iff u(x) \\geq u(y)] \\iff\n[x \\geq y \\iff x \\succcurlyeq y] \\iff\n\\succcurlyeq monotone\nThe third line uses the definition of utility function: u(x) \\geq u(y) if and only if x \\succcurlyeq y.\n\nAnalogously for the second part:\n\nu strictly increasing \\iff\n[x &gt; y \\iff u(x) &gt; u(y)] \\iff\n[x &gt; y \\iff x \\succ y] \\iff\n\\succcurlyeq striclty monotone\nQED.",
    "crumbs": [
      "Lectures 1 – 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Properties of Preferences and Utility Functions</span>"
    ]
  },
  {
    "objectID": "prop-pref-utilityfun.html#local-nonsatiation",
    "href": "prop-pref-utilityfun.html#local-nonsatiation",
    "title": "2  Properties of Preferences and Utility Functions",
    "section": "2.2 Local-Nonsatiation",
    "text": "2.2 Local-Nonsatiation\n\n\n\n\n\n\nMeaning\n\n\n\n“No bliss points” (not even local ones)\n\n\nLet B_{\\varepsilon}(x) = \\{{y:|x-y| &lt; \\varepsilon}\\}\n\nDefinition 2.2 \\quad \\succcurlyeq is locally non-satiated if for any x and \\varepsilon &gt; 0 there exists y \\in B_{\\varepsilon}(x) with y \\succ x\n\nIf u represents \\succcurlyeq, then t is locally non-satiated if and only if u has no local maximum. (Prove this!)",
    "crumbs": [
      "Lectures 1 – 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Properties of Preferences and Utility Functions</span>"
    ]
  },
  {
    "objectID": "prop-pref-utilityfun.html#convexity",
    "href": "prop-pref-utilityfun.html#convexity",
    "title": "2  Properties of Preferences and Utility Functions",
    "section": "2.3 Convexity",
    "text": "2.3 Convexity\n\n\n\n\n\n\nMeaning\n\n\n\n“Diversity is good”\n\n\n\nDefinition 2.3 \\quad \\succcurlyeq is convex if x \\succcurlyeq y, x' \\succcurlyeq y and \\alpha \\in [0,1] imply:\n\\alpha x + (1-\\alpha)x' \\succcurlyeq y\\succcurlyeq is strictly convex if x \\succcurlyeq y, x' \\succcurlyeq y, \\alpha \\in (0,1) and x \\neq x' imply:\n\\alpha x + (1-\\alpha)x' \\succ y\n\nDoes this make sense? Is \\left(\\frac{1}{2}\\right)beer + \\left(\\frac{1}{2}\\right)wine a good thing?\nWe now discuss several properties of convex preferences.\n\nContour Sets\nFor x \\in X, the upper contour set of x is\n\nS(x) = \\{y \\in X: y \\succcurlyeq x\\}\n\n\nTheorem 2.2 \\quad \\succcurlyeq is convex \\iff U(s) is a convex set for every x \\in X.\n\n\n\n\n\n\n\nProof\n\n\n\n\nProof of sufficiency (\\Rightarrow):\nAssume \\succcurlyeq convex. We have to show that S(x) is convex. To do so, take any two elements y, y' \\in S(x).\nBy definition of S(x), y, y' \\in S(x) means that y \\succcurlyeq x and y' \\succcurlyeq x\nConvexity then implies that for all \\alpha \\in [0,1], \\alpha y + (1-\\alpha)y' \\succcurlyeq x.\nBut this implies that \\alpha y + (1-\\alpha)y' \\in U(x).\nIn short: we showed that y, y' \\in S(x) \\Rightarrow \\alpha y + (1-\\alpha)y' \\in U(x) for all \\alpha \\in [0,1].\nThis means that S(x) is convex.\nProof of necessity (\\Leftarrow):\nWe will prove by contradiction. Assume S(x) is convex, but \\succcurlyeq is not convex. We have to find an absurd conclusion.\nAssume \\succcurlyeq is not convex. Then there are \\alpha \\in (0,1), y, y' and x such that y \\succcurlyeq x, y' \\succcurlyeq x but x \\succ \\alpha y + (1-\\alpha)y'. This implies that S(x) is not convex.\nIn short: we showed that if \\succcurlyeq is not convex, then S(x) is not convex for some x. This is equivalent to showing that S(x) \\Rightarrow \\succcurlyeq convex.\n\nQED.\n\n\nThat’s why convex preferences are called convex: for every x, the set of all alternatives preferred to x is convex. When the context is clear, we will write simply S instead of S(x), and interpret it as the set of alternatives preferred to some unspecified x.\n\n\nSet of Maximizers\n\nTheorem 2.3 \\quad If \\succcurlyeq is convex, then for any convex choice set B, the set C^*(B,\\succcurlyeq) is convex. If \\succcurlyeq is convex, then for any convex choice set B, the set C^*(B,\\succcurlyeq) is single-valued (for empty).\n\n\n\n\n\n\n\nProof\n\n\n\n\nFirst part:\nTake any x \\in B\nIf y,y'\\in C^*(B,\\succcurlyeq), then y \\succcurlyeq x and y' \\succcurlyeq x.\nConvexity then implies that for all \\alpha \\in [0,1], \\alpha y + (1-\\alpha)y' \\succcurlyeq x.\nSince this holds for any x \\in B, it follows that \\alpha \\in [0,1], \\alpha y + (1-\\alpha)y' \\in C^*(B,\\succcurlyeq).\nThat is, C^*(B,\\succcurlyeq) is convex.\nSecond part:\nAssume there are x, x' \\in C^*(B,\\succcurlyeq) with x \\neq x'.\nThen x \\succcurlyeq x and x' \\succcurlyeq x: definition of optimal choices.\nStrict convexity then implies that for all \\alpha \\in [0,1], one has \\alpha x +(1-\\alpha)x' \\succ x.\nBut the first part of the theorem implies \\alpha x +(1-\\alpha)x' \\in C^*(B,\\succcurlyeq).\n\nIn words: if there are two different optimal choices with strictly convex preferences, then it is possible to find an alternative that is strictly better than at least one of them. This is absurd as the DM should have chosen this alternative.\nQED.\n\n\n\n\nConvexity: Utility Functions\nThe characteristic of utility functions that represent convex preferences is quasi-concavity.\n\nDefinition 2.4 A function u:X \\rightarrow \\mathbb{R} is quasi-concave if, for every x,y with u(x) \\geq u(y) and every \\alpha \\in (0,1),\n\nu(\\alpha x + (1-\\alpha)y) \\geq u(y)\n A function u:X \\rightarrow \\mathbb{R} is strictly quasi-concave if, for every x,y with u(x) \\geq u(y), x \\neq y and every \\alpha \\in (0,1),\n\nu(\\alpha x + (1-\\alpha)y) &gt; u(y)\n\n\n\nTheorem 2.4 \\quad u is quasi-concave \\iff for every r \\in \\mathbb{R} the upper contour set S = \\{x \\in X: u(x) \\geq r\\} is convex.\n\nNotation: this is the same set of ‘preferred alternatives’ we used before. We may write S(x) if we want to highlight that these alternatives are preferred to some specific x. Analogously, we may write S(r) to highlight that these alternatives achieve a level of utility no lower than r. If the alternative x or the choice r are generic, we may write simply S.\n\n\n\n\n\n\nProof\n\n\n\n\nProof of sufficiency (\\Rightarrow):\n\nTake any r \\in \\mathbb{R}.\nTake two elements of S = \\{x \\in X: u(x) \\geq r\\}. That is, take x,x' such that u(x), u(x') \\geq r.\nAssume without loss of generality that u(x) \\geq u(x').\nThen:\n\nu(\\alpha x + (1-\\alpha)x') \\underbrace{\\geq}_{quasi-concavity} u(x') \\geq r\n This implies \\alpha x + (1-\\alpha)x' \\in \\{x \\in X: u(x) \\geq r\\}\nThis holds for any two elements in the upper contour set S = \\{x \\in X: u(x) \\geq r\\}, and any \\alpha \\in [0,1]. It follows that this set is convex.\n\nProof of necessity (\\Leftarrow):\n\nAssume there is some r \\in \\mathbb{R}, some \\alpha \\in (0,1) and x,x' \\in S = \\{x \\in X: u(x) \\geq r\\} such that:\n\n\\alpha x + (1-\\alpha)x' \\notin S = \\{x \\in X: u(x) \\geq r\\}\n That is, S is not convex. This meand that u(x) \\geq r, u(x') \\geq r but u(\\alpha x + (1-\\alpha)x') &lt; r, for some r \\in \\mathbb{R} and some \\alpha \\in (0,1).\nThis means that u is not quasi-concave.\nIn short, we showed that if S is not convex for all r \\in \\mathbb{R}, then u is not quasi-concave. This is equivalent to showing that if u is quasi-concave, then S is convex for all u.\nQED.\n\n\n\nTheorem 2.5 Suppose utility function u represents preferences \\succcurlyeq. Then:\nu quasi-concave \\iff \\succcurlyeq convex\nu strictly quasi-concave \\iff \\succcurlyeq strictly convex\n\n\n\n\n\n\n\nExercise\n\n\n\nProve this theorem. Proof follows directly from Theorem 2.4.\n\n\nWarning: convex preferences are represented by quasi-concave utility functions. Convex preferences get that name because they make upper contour sets convex. Quasi-concave utility functions get that name because quasi-concavity is a weaker property than concavity.",
    "crumbs": [
      "Lectures 1 – 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Properties of Preferences and Utility Functions</span>"
    ]
  },
  {
    "objectID": "prop-pref-utilityfun.html#separability",
    "href": "prop-pref-utilityfun.html#separability",
    "title": "2  Properties of Preferences and Utility Functions",
    "section": "2.4 Separability",
    "text": "2.4 Separability\nOften very useful to restrict ways in which a consumer’s preferences over one kind of good can depend on consumption of other goods. If allowed arbitrary interdependencies, would need to observe consumer’s entire consumption bundle to infer anything. Properties of preferences that separation among different kinds of goods are called separability properties.\n\nWeak Separability: Preferences\n\n\n\n\n\n\nMeaning\n\n\n\n“Preferences over one kind of goods don’t depend on what other goods are consumed”\n\n\n\nDefinition 2.5 \\succcurlyeq is weakly separable in J_1,J_2 if for k=1,2 and for every x_{J_{k}} and x'_{J_{k}} and for every x_{J^{c}_{k}} and x'_{J^{c}_{k}} one has:\n\n(x_{J_{k}}, x_{J^{c}_{k}}) \\succcurlyeq (x'_{J_{k}}, x_{J^{c}_{k}}) \\iff (x_{J_{k}}, x'_{J^{c}_{k}}) \\succcurlyeq (x'_{J_{k}}, x'_{J^{c}_{k}})\n\nMay extend for than two subsets of X.\n\n\n\nWeak Separability: Utility\n\nTheorem 2.6 Preferences are weakly separable in J_1,J_2 if and only if utility function (if it exists) is:\n\nu(x) = v(u_1(x_{J_{1}}), u_2(x_{J_{2}}), u(x_{(J_1 \\cup J_2)^C}))\n\n\n\n\nOther Kinds of Separability\n\nStrong separability: utility is additively separable\n\n\nu(x) = u_1(x_{J_{1}}) + u_2(x_{J_{2}})\n\n\nQuasi-linear utility\n\n\nu(x)= x_1 + v(x_2,\\dots,x_n)",
    "crumbs": [
      "Lectures 1 – 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Properties of Preferences and Utility Functions</span>"
    ]
  }
]